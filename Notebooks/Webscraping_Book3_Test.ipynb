{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c274e996-305c-4d15-9f89-6101fd0d20bb",
   "metadata": {},
   "source": [
    "**Task Instructions for Students**:\n",
    "\n",
    "**Objective**: Scrape and extract data about public universities in Germany from the Hochschulkompass website (https://www.hochschulkompass.de/en/study-in-germany.html). Specifically, you will extract the following information for each university:\n",
    "\n",
    "1) Name of the University\n",
    "2) Location\n",
    "3) Governining body\n",
    "4) Number of students\n",
    "5) Founding year\n",
    "6) Link to the website of the University\n",
    "\n",
    "You will then save this information in a CSV file/dataframe for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00dd81-d4c0-425e-88bd-244438865f2c",
   "metadata": {},
   "source": [
    "**Steps**:\n",
    "\n",
    "1) *Navigate to the Hochschulkompass Website*:\n",
    "\n",
    "Open the Hochschulkompass website: https://www.hochschulkompass.de/en/study-in-germany.html.\n",
    "\n",
    "2) *Search for Public Universities:*\n",
    "\n",
    "- Use the search functionality to filter the list of universities to only display public universities.\n",
    "- You can use the filter options available on the site (e.g., school type, type of control, etc.) to narrow down the search results.\n",
    "\n",
    "3) Use Selenium to Automate the Process:\n",
    "\n",
    "- Write a Selenium script to automate the following tasks:\n",
    "  - Perform the search to list public universities.\n",
    "  - Navigate through the search results pages.\n",
    " \n",
    "- Use Selenium to interact with the website, and then use Beautiful Soup to parse the HTML of each page to extract the required information.\n",
    "\n",
    "4) Extract University Details Using Beautiful Soup:\n",
    "\n",
    "- For each university, extract the following details using Beautiful Soup:\n",
    "   - Name of the University\n",
    "   - Location\n",
    "   - Governing Body\n",
    "   - Number of Students\n",
    "   - Founding Year\n",
    "   - Link to the website of the University\n",
    " \n",
    "- Use Beautiful Soup’s parsing capabilities to locate and extract the text content of relevant HTML elements.\n",
    "\n",
    "5) Save Data to CSV:\n",
    "\n",
    "Use Python’s csv module or pandas to save the extracted data into a CSV file.\n",
    "Each row in the CSV should correspond to a different university, with columns for Name, Location, Governing Body, Number of Students, Founding Year and Link.\n",
    "\n",
    "\n",
    "6) Handle Multiple Pages:\n",
    "\n",
    "If the results span multiple pages, ensure your script can handle pagination and continues to scrape data from all available pages.\n",
    "\n",
    "7) Comment Your Code:\n",
    "\n",
    "Make sure to comment on your code to explain what each part does. This will help others understand your approach and logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f5f019-32f9-4641-b9ab-2f0efebac4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from get_chrome_driver import GetChromeDriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efd409-15b6-4831-99c8-8681049a9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_driver = GetChromeDriver()\n",
    "get_driver.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f986d5-a8f9-4deb-ad39-a1a252e00c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") # enabling headless mode aka you won't see the browser --your choice\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc5f96-a0e6-49df-93b0-09aac1177a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(\"https://www.hochschulkompass.de/en/higher-education-institutions/search-for-a-higher-education-institution.html?tx_szhrksearch_pi1%5Bsearch%5D=1&tx_szhrksearch_pi1%5BQUICK%5D=1&tx_szhrksearch_pi1%5Bname%5D=&tx_szhrksearch_pi1%5Bhstype%5D%5B1%5D=1&tx_szhrksearch_pi1%5Btraegerschaft%5D=1\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af645c-f46c-4d36-a80e-28986924babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Click the \"Results per page\" dropdown\n",
    "\n",
    "# Wait until the \"Results per page\" dropdown is clickable\n",
    "results_dropdown = WebDriverWait(driver, 15).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"________\"))\n",
    ")  # HINT: Find the element that contains the text '10' in the dropdown menu\n",
    "\n",
    "# Click on the dropdown to open it\n",
    "results_dropdown.________()  # HINT: What method do you use to simulate a click on a web element?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5635e1b-89cc-4c34-8234-b67dbeda3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Select \"100\" from the dropdown options\n",
    "\n",
    "# Wait until the \"100\" option is clickable\n",
    "option_100 = WebDriverWait(driver, 15).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"________\"))\n",
    ")  # HINT: Look for the element with class 'jcf-option' and text '100'\n",
    "\n",
    "# Click on the \"100\" option\n",
    "option_100.________()  # HINT: What method is used to click a web element?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0404f-bb36-4240-ac69-94843b6ae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find all \"Learn More\" links on the page\n",
    "\n",
    "# Locate all elements with \"Learn More\" in the link text\n",
    "learn_more_links = driver.find_elements(By.XPATH, \"________\")  \n",
    "# HINT: What XPath would you use to find all links containing the text 'Learn More'?\n",
    "\n",
    "# Step 4: Extract the href attribute from each link and store it in a list\n",
    "\n",
    "# Use list comprehension to extract the 'href' attribute\n",
    "learn_more_urls = [link.get_attribute('________') for link in learn_more_links]\n",
    "# HINT: Which attribute of an anchor tag (<a>) contains the URL?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be233899-57c6-4852-9576-30316e09a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df03cc1-9eae-4665-827a-7ce4f381657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92032b0-6c13-479c-ae87-e0e37d32b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = []\n",
    "meta_data_links = []\n",
    "\n",
    "for i in range(len(learn_more_urls)):\n",
    "    print(i)\n",
    "    driver.get(learn_more_urls[i])\n",
    "    time.sleep(2)  # Pause to ensure the page has time to load\n",
    "    \n",
    "    # Wait for the page to load fully (adjust the locator if necessary)\n",
    "    WebDriverWait(driver, 15).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"________\"))\n",
    "    )  # HINT: What class name indicates the university details section?\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, '________')\n",
    "    # HINT: What parser should be used with BeautifulSoup for HTML content?\n",
    "    \n",
    "    # Extract the university information section\n",
    "    uni_info = soup.find('div', {'class': '________'})\n",
    "    # HINT: What class name contains the university's detailed information?\n",
    "    \n",
    "    # Extract the university logo section\n",
    "    link_info = soup.find('div', {'class': '________'})\n",
    "    # HINT: What class name contains the university's logo information?\n",
    "    \n",
    "    # Store the extracted information in the lists\n",
    "    meta_data.append(uni_info)\n",
    "    meta_data_links.append(link_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ac1d0-1880-412f-a2d2-aac16154851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_Uni = []\n",
    "Governing_Body = []\n",
    "Number_of_Students = []\n",
    "Founding_Year = []\n",
    "Federal_State = []\n",
    "\n",
    "for elem in meta_data:\n",
    "    # Assume elem is already the 'uni-steckbrief' BeautifulSoup object from the previous step\n",
    "    try:\n",
    "        # Extract the university name\n",
    "        Name_Uni.append(elem.find(class_=\"________\").get_text(strip=True))\n",
    "        # HINT: What class name is used to find the university's name?\n",
    "        \n",
    "        details = elem.find('ul').find_all('li')\n",
    "        \n",
    "        # Extract the governing body\n",
    "        Governing_Body.append(details[0].find(class_='________').get_text(strip=True))\n",
    "        # HINT: What class name holds the descriptive text for each detail?\n",
    "        \n",
    "        # Extract the number of students\n",
    "        Number_of_Students.append(details[1].find(class_='________').get_text(strip=True))\n",
    "        # HINT: What class name holds the descriptive text for each detail?\n",
    "        \n",
    "        # Extract the founding year\n",
    "        Founding_Year.append(details[________].find(class_='________').get_text(strip=True))\n",
    "        # HINT: Which index corresponds to the founding year? What class name holds the descriptive text?\n",
    "        \n",
    "        # Extract the federal state\n",
    "        Federal_State.append(details[________].find(class_='________').get_text(strip=True))\n",
    "        # HINT: Which index corresponds to the federal state? What class name holds the descriptive text?\n",
    "    \n",
    "    except (IndexError, AttributeError) as e:\n",
    "        # Handle cases where the structure is not as expected\n",
    "        Name_Uni.append(None)\n",
    "        Governing_Body.append(None)\n",
    "        Number_of_Students.append(None)\n",
    "        Founding_Year.append(None)\n",
    "        Federal_State.append(None)\n",
    "        print(f\"Error processing element: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460d4b2-3a15-4a92-b145-68183f8bd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Link_University = []\n",
    "for elem in meta_data_links:\n",
    "    \n",
    "    try:\n",
    "        # Extract the 'href' attribute of the anchor tag\n",
    "        Link_University.append(elem.find('a')['________'])  \n",
    "        # HINT: What attribute of an anchor tag (<a>) contains the URL?\n",
    "    except:\n",
    "        # Handle cases where the structure is not as expected\n",
    "        Link_University.append(________)  \n",
    "        # HINT: What should you append if the link is not found?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c7744-2659-4513-8ae4-747124fc914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_dict = {\n",
    "    'University_Name':Name_Uni ,\n",
    "    'Governing_Body': Governing_Body,\n",
    "    'Number_of_Students': Number_of_Students,\n",
    "    'Founding_Year': Founding_Year,\n",
    "    'Federal_State': Federal_State,\n",
    "    'University_Link': Link_University\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
