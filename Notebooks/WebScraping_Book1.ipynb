{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49a8d6a7-9825-4bc0-9612-0ab05e34942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4650d4-99d4-4ebb-989a-63d39b1124bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HTML file\n",
    "with open('C:\\\\Users\\\\shahania\\\\Documents\\\\Phd\\\\HERSS Summer School\\\\Tutorial\\\\Test_HTML_1.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8ea55-3006-4a54-a866-f3612c4a8b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Print the parsed HTML with proper indentation\n",
    "print(soup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dd6acd8-2a73-4c8b-94f3-19905dc472fb",
   "metadata": {},
   "source": [
    "**Handing Malformed HTML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10530885-2d95-4271-8078-768ec5f835a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<section>\n",
      " <h2>\n",
      "  Content Section\n",
      " </h2>\n",
      " <p class=\"content\">\n",
      "  Here is some\n",
      "  <b>\n",
      "   bold\n",
      "  </b>\n",
      "  text and\n",
      "  <i>\n",
      "   italic\n",
      "  </i>\n",
      "  text.\n",
      " </p>\n",
      " <p class=\"content\">\n",
      "  Another paragraph with a\n",
      "  <a href=\"http://example.com\">\n",
      "   link\n",
      "  </a>\n",
      "  .\n",
      " </p>\n",
      " <p class=\"content\">\n",
      "  This paragraph is missing a closing tag for\n",
      "  <i>\n",
      "   italic text.\n",
      "  </i>\n",
      " </p>\n",
      "</section>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "malformed_html = '''\n",
    "<section>\n",
    "    <h2>Content Section</h2>\n",
    "    <p class=\"content\">Here is some <b>bold</b> text and <i>italic</i> text.</p>\n",
    "    <p class=\"content\">Another paragraph with a <a href=\"http://example.com\">link</a>.</p>\n",
    "    <p class=\"content\">This paragraph is missing a closing tag for <i>italic text.\n",
    "</section>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(malformed_html, 'html.parser')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec861722-e734-41e6-b4ec-e68162d3be88",
   "metadata": {},
   "source": [
    "**Search and Extract Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c316c8b0-fd69-497e-b3cd-32225446d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sample Web Page for Web Scraping\n",
      "Paragraph 1: This is a simple page for demonstrating web scraping with Beautiful Soup.\n",
      "Paragraph 2: This page contains various HTML elements that can be extracted using Beautiful Soup.\n",
      "Paragraph 3: It also includes some deliberately malformed HTML to demonstrate error handling.\n",
      "Paragraph 4: Here is some bold text and italic text.\n",
      "Paragraph 5: Another paragraph with a link.\n",
      "Paragraph 6: This paragraph is missing a closing tag for italic text.\n",
      "    \n",
      "Paragraph 7: © 2024 Sample Web Page\n",
      "Link Text: link, URL: http://example.com\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract the title\n",
    "title = soup.title.string\n",
    "print(f\"Title: {title}\")\n",
    "\n",
    "# Find all paragraphs\n",
    "paragraphs = soup.find_all('p')\n",
    "for i, p in enumerate(paragraphs, start=1):\n",
    "    print(f\"Paragraph {i}: {p.get_text()}\")\n",
    "\n",
    "# Find and print the link\n",
    "link = soup.find('a')\n",
    "print(f\"Link Text: {link.get_text()}, URL: {link['href']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0399b3-ed9a-482e-8e04-b81a8fdcec8c",
   "metadata": {},
   "source": [
    "**HTML/XML parsing + Integration with Parsers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fe3a39-e68a-4829-aad9-9d79f17121f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title using lxml: Sample Web Page for Web Scraping\n",
      "Title using html.parser: Sample Web Page for Web Scraping\n"
     ]
    }
   ],
   "source": [
    "soup_lxml = BeautifulSoup(html_content, 'lxml')\n",
    "print(f\"Title using lxml: {soup_lxml.title.string}\")\n",
    "\n",
    "# Alternatively, parse the HTML content with the default html.parser\n",
    "soup_html_parser = BeautifulSoup(html_content, 'html.parser')\n",
    "print(f\"Title using html.parser: {soup_html_parser.title.string}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01ff16-5115-409c-9a37-27f8cde4a566",
   "metadata": {},
   "source": [
    "**Text Manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489a995-a6d5-42e3-8ff5-7eefe73ffe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the title\n",
    "soup.title.string = \"Updated Sample Web Page Title\"\n",
    "\n",
    "# Add a new paragraph\n",
    "new_paragraph = soup.new_tag('p')\n",
    "new_paragraph.string = \"This is a new paragraph added to the content section.\"\n",
    "soup.body.append(new_paragraph)\n",
    "\n",
    "# Print the modified HTML\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448f589-7de0-4d8f-aa9b-f519acfd0225",
   "metadata": {},
   "source": [
    "**Let's try with the website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "139b2a44-791c-4faf-885f-09e2ca8a071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'\n",
    "} # \n",
    "url = 'https://www.goodreads.com/'\n",
    "response = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a5585c-2636-49d9-9b92-8857fe15b5c0",
   "metadata": {},
   "source": [
    "Beautiful Soup does not handle HTTP requests or handle JavaScript. It focuses entirely on parsing HTML/XML documents. You typically use it in combination with libraries like requests to fetch web pages and then use Beautiful Soup to extract the data you need from those pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faeca86-c589-4f71-8431-d29226415477",
   "metadata": {},
   "source": [
    "**Headers, specifically the User-Agent header, play a crucial role in making your HTTP requests appear more like those from a regular browser.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0a2f8-241c-4c3b-8ac0-8997edecb05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69c4d6-3ffc-457f-ab56-68b2eb68a401",
   "metadata": {},
   "source": [
    "If the content is missing, inspect the source of the Goodreads page in your browser (right-click and select \"View Page Source\") and compare it with what you get from requests. If they differ, it means the content is being rendered by JavaScript after the initial page load. That's where Selenium comes in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6c3a16f-d96e-46eb-8e27-ab37aaf739bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Goodreads | Meet your next favorite book\n"
     ]
    }
   ],
   "source": [
    "# 1. Using find() to find the first occurrence of a specific tag or class\n",
    "# Let's find the title of the page\n",
    "page_title = soup.find('title').get_text()\n",
    "print(f\"Page Title: {page_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5e9ce4-d0ad-49c0-9daa-803bf3fe63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footer Links:\n",
      "About us\n",
      "Careers\n",
      "Terms\n",
      "Privacy\n",
      "Interest Based Ads\n",
      "Ad Preferences\n",
      "Help\n",
      "Authors\n",
      "Advertise\n",
      "Authors & ads blog\n",
      "API\n",
      "Mobile version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Using find_all() to find all occurrences of a tag\n",
    "# Find all the links in the footer\n",
    "footer_links = soup.find_all('a', class_='responsiveSiteFooter__link')\n",
    "print(\"Footer Links:\")\n",
    "for link in footer_links:\n",
    "    print(link.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b09276f-b4f8-455b-b65d-8e453507f35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promo Headline: \n",
      "Discover & read more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Using select() to find elements using CSS selectors\n",
    "# Find the main promo headline using a CSS selector\n",
    "promo_headline = soup.select('div.promoHeader__promoMastheadContent h2')[0].get_text()\n",
    "print(f\"Promo Headline: {promo_headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c581c9e9-47cd-48c7-8e8f-d755252ab6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent of the first footer link: li\n"
     ]
    }
   ],
   "source": [
    "# 4. Using parent to navigate to the parent element\n",
    "# Find the parent of the first footer link\n",
    "first_footer_link = soup.find('a', class_='responsiveSiteFooter__link')\n",
    "footer_parent = first_footer_link.parent\n",
    "print(f\"Parent of the first footer link: {footer_parent.name}\")  # This should print the name of the parent tag, e.g., 'li'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4b18b6-0434-4692-8e15-c8b026bc9f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 5. Using next_sibling to navigate to the next sibling\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Find the next sibling after the first footer link\u001b[39;00m\n\u001b[0;32m      3\u001b[0m next_sibling \u001b[38;5;241m=\u001b[39m first_footer_link\u001b[38;5;241m.\u001b[39mfind_next_sibling()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext sibling after the first footer link: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_sibling\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# 5. Using next_sibling to navigate to the next sibling\n",
    "# Find the next sibling after the first footer link\n",
    "next_sibling = first_footer_link.find_next_sibling()\n",
    "print(f\"Next sibling after the first footer link: {next_sibling.get_text()}\")  # Should be the text of the next link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748aae3-c042-4938-913b-407a7f7a94ea",
   "metadata": {},
   "source": [
    "Because we have no sibling here. \n",
    "\n",
    "*What is a sibling?*\n",
    "\n",
    "<div class=\"family\">\r\n",
    "    <div class=\"parent\">\r\n",
    "        <p>Child 1</p>\r\n",
    "        <p>Child 2</p>\r\n",
    "        <p>Child 3</p>\r\n",
    "   </\n",
    "</div>viv>\r\n",
    "<\n",
    "\n",
    "Parent:\n",
    "\n",
    "The element directly above another element in the hierarchy.\n",
    "In the example, the <div class=\"parent\"> is the parent of <p> elements (Child 1, Child 2d3), Chil\n",
    "\n",
    "Children:\n",
    "\n",
    "Elements directly below another element in the hierarchy.\n",
    "The <p> elements are children of the <div class=\"parent\">.\n",
    "\n",
    "\n",
    "Siblings:\n",
    "\n",
    "Elements that share the same parent.\n",
    "In the example, \"Child 1\", \"Child 2\", and \"Child 3\" are siblings because they all share the same parent <div classnt\"> <\"pare\n",
    "/div>\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e54f889-deac-4deb-aae7-1f21238d3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First genre: Art\n"
     ]
    }
   ],
   "source": [
    "# Find the first genre link\n",
    "first_genre = soup.find('a', href=\"/genres/art\")\n",
    "print(f\"First genre: {first_genre.get_text()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4eba728-964d-4b02-8b89-9f66f35b11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next genre: Biography\n"
     ]
    }
   ],
   "source": [
    "# Find the next sibling genre link\n",
    "next_genre = first_genre.find_next_sibling('a')\n",
    "print(f\"Next genre: {next_genre.get_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ab04564-2274-43b6-8749-9466e246aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third genre: Business\n"
     ]
    }
   ],
   "source": [
    "# Find the next sibling again\n",
    "third_genre = next_genre.find_next_sibling('a')\n",
    "print(f\"Third genre: {third_genre.get_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93cea563-2947-4f40-9611-3387cc450d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous sibling of the next link: Biography\n"
     ]
    }
   ],
   "source": [
    "# 6. Using previous_sibling to navigate to the previous sibling\n",
    "# Find the previous sibling of the next sibling (should bring us back to the first link)\n",
    "previous_sibling = third_genre.find_previous_sibling('a')\n",
    "print(f\"Previous sibling of the next link: {previous_sibling.get_text()}\")  # Should be the text of the first link again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2407629-ef32-4f7b-9146-b0949cd9df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous sibling of the next link: Art\n"
     ]
    }
   ],
   "source": [
    "# 6. Using previous_sibling to navigate to the previous sibling\n",
    "# Find the previous sibling of the next sibling (should bring us back to the first link)\n",
    "first_genre_again  = previous_sibling.find_previous_sibling('a')\n",
    "print(f\"Previous sibling of the next link: {first_genre_again.get_text()}\")  # Should be the text of the first link again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6ac801f-492e-4238-ac21-a1d41b85c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific parent of 'About Us' link: ul\n"
     ]
    }
   ],
   "source": [
    "# 7. Using find_parent to find a specific parent element\n",
    "# Find the parent of a specific link using find_parent\n",
    "specific_link = soup.find('a', href='/about/us')\n",
    "specific_parent = specific_link.find_parent('ul')\n",
    "print(f\"Specific parent of 'About Us' link: {specific_parent.name}\")  # Should be 'ul'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02bbdcbb-47da-4116-ba1a-d6c0488f8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Images:\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1480106986l/33917._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1631251689l/4214._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1563042852l/49628._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1479863624l/1618._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1409595968l/929._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1529026760l/39832183._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1722456144l/43641._SX98_.jpg\n",
      "https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1622355533l/4667024._SX98_.jpg\n"
     ]
    }
   ],
   "source": [
    "# 8. Using find_all to find all images with a specific class\n",
    "# Find all book images in the feature teaser boxes\n",
    "book_images = soup.find_all('img', class_='bookImgSimilar')\n",
    "print(\"Book Images:\")\n",
    "for img in book_images:\n",
    "    print(img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aadbf8ac-8b72-43aa-a1f2-1d71fbdbfa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "React Components with data-react-class:\n",
      "ReactComponents.StoresInitializer\n",
      "ReactComponents.GoogleBannerAd\n",
      "ReactComponents.EditorialBlogThumbnail\n",
      "ReactComponents.GoogleBannerAd\n"
     ]
    }
   ],
   "source": [
    "# 9. Using select to find elements by attribute\n",
    "# Use a CSS selector to find an element by its attribute (e.g., data-react-class)\n",
    "react_components = soup.select('[data-react-class]')\n",
    "print(\"React Components with data-react-class:\")\n",
    "for component in react_components:\n",
    "    print(component['data-react-class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b5afefc-aa10-457d-95fd-62db64855388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best quotes link: /quotes\n"
     ]
    }
   ],
   "source": [
    "# 10. Using find to find an element with a specific text\n",
    "# Find a link containing specific text\n",
    "best_quotes_link = soup.find('a', string='Best quotes')\n",
    "print(f\"Best quotes link: {best_quotes_link['href']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817a30e-3617-4f24-ac4a-c85ad810cd88",
   "metadata": {},
   "source": [
    "**When to use what**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68ad10-6486-45cc-b213-4494ee68a271",
   "metadata": {},
   "source": [
    "1. find()\n",
    "When to Use: Use find() when you want to locate the first occurrence of a specific tag or element that matches your criteria.\n",
    "2. find_all()\n",
    "When to Use: Use find_all() when you need to retrieve all elements that match a specific tag or criteria.\n",
    "3. select()\n",
    "When to Use: Use select() when you need to find elements using complex CSS selectors. It’s very powerful for matching based on classes, IDs, or nested elements.\n",
    "\n",
    "4. find_parent() and parent\n",
    "When to Use: Use these methods to navigate upwards in the DOM tree to find the parent of a specific element.\n",
    "5. find_next_sibling() and find_previous_sibling()\n",
    "When to Use: Use these methods to navigate sideways in the DOM tree to find the next or previous sibling of an element. It’s useful when dealing with elements at the same level. (Example: Finding the next and previous paragraphs around a specific paragraph)\n",
    "\n",
    "6. children\n",
    "When to Use: Use children when you want to iterate over all direct children of an element. This is useful for navigating elements that contain nested elements.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
